{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "2gdo2_8VfNxW",
        "OHW5HuxtXAW_"
      ],
      "authorship_tag": "ABX9TyN9NAFBZbXh+BhF7l/Qr/8B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimanirobbi/wk-7-ai/blob/main/part_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Short Answer Questions"
      ],
      "metadata": {
        "id": "2gdo2_8VfNxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q1: Define algorithmic bias and provide two examples.**\n",
        "**Algorithmic bias** refers to systematic and repeatable errors in a computer system that create unfair outcomes, such as privileging one arbitrary group of users over others. It occurs when an AI system produces results that are systematically prejudiced due to erroneous assumptions in the machine learning process.\n",
        "\n",
        "**Examples:**\n",
        "\n",
        "**Hiring Algorithms:** Amazon's recruiting tool was biased against female candidates because it was trained on resumes submitted over a 10-year period, which came predominantly from men. The algorithm learned to penalize resumes that included words like \"women's\" or graduates of all-women's colleges.\n",
        "\n",
        "**Predictive Policing:** Predictive policing software like PredPol was found to target minority neighborhoods disproportionately. This was because the training data was based on historical arrest data, which itself reflected biased policing practices, creating a feedback loop of over-policing.\n",
        "\n",
        "## **Q2: Explain the difference between transparency and explainability in AI.**\n",
        "- **Transparency** is about the \"what\" and \"how.\" It refers to the openness about the AI system's existence, its purpose, its data sources, and its high-level functioning. A transparent system makes it clear that an AI is being used and for what goal.\n",
        "\n",
        "- **Explainability** is about the \"why.\" It refers to the ability to understand and articulate the internal reasoning of an AI model for a specific decision or output. It answers why a loan was denied, or why a specific medical diagnosis was suggested.\n",
        "\n",
        "**Why both are important:** Transparency builds trust with users and regulators by being open about AI use. Explainability ensures accountability and allows for debugging, fairness auditing, and challenging incorrect decisions. Without both, AI systems become \"black boxes\" that can perpetuate bias unchecked.\n",
        "\n",
        "## **Q3: How does GDPR impact AI development in the EU?**\n",
        "The GDPR impacts AI development significantly by enforcing strict principles around data and individual rights:\n",
        "\n",
        "- **Lawful Basis for Processing:** Requires a clear legal reason (e.g., explicit consent) for using personal data in AI training sets.\n",
        "\n",
        "- **Right to Explanation:** Gives individuals the right to obtain an explanation for automated decisions (like loan rejections) that significantly affect them.\n",
        "\n",
        "- **Data Minimization and Purpose Limitation:** Forces developers to use only the data strictly necessary for the specified AI purpose, preventing function creep.\n",
        "\n",
        "- **Right to Erasure (\"Right to be Forgotten\"):** Allows individuals to have their data deleted, which poses a challenge for AI models already trained on that data.\n",
        "\n",
        "- **Privacy by Design and by Default:** Mandates that data protection measures are integrated into the development of AI systems from the outset"
      ],
      "metadata": {
        "id": "JSGT2HXbW_Xg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Ethical Principles Matching"
      ],
      "metadata": {
        "id": "OHW5HuxtXAW_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Ensuring AI does not harm individuals or society. → **(B) Non-maleficence**\n",
        "\n",
        "- Respecting users’ right to control their data and decisions. → **(C) Autonomy**\n",
        "\n",
        "- Designing AI to be environmentally friendly. → **(D) Sustainability**\n",
        "\n",
        "- Fair distribution of AI benefits and risks. → **(A) Justice**"
      ],
      "metadata": {
        "id": "bU5AGWmdgYbl"
      }
    }
  ]
}